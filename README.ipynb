# AI Ethics Skill Profiler

KI-gestütztes Analyse- und Reflexionstool zur Bewertung von Fairness, Bias und ethischen Risiken in Machine-Learning-Modellen.  
Das Projekt verbindet sozialwissenschaftliche Ethik-Konzepte mit technischer Modellanalyse und erklärbarer KI.

---

## Projektziel
Der AI Ethics Skill Profiler unterstützt dabei,
- Verzerrungen (Bias) in ML-Modellen sichtbar zu machen
- Fairness zwischen Gruppen zu analysieren
- ethische Risiken systematisch zu reflektieren
- Responsible-AI-Prinzipien technisch umzusetzen

Zielgruppen sind Forschung, Lehre, Responsible-AI-Teams und technisch-ethische Evaluation.

---

## Projektstruktur
ai_ethics_skill_profiler/
│
├── data/ # optionale Rohdaten (nicht versioniert)
│
├── models/ # gespeicherte ML-Modelle & Testdaten
│ ├── iris_model.keras
│ ├── X_test.npy
│ ├── y_test.npy
│ └── groups_test.npy
│
├── src/
│ ├── train_model.py # Training & Speichern des Modells
│ ├── load_model.py # Laden von Modell & Daten
│ ├── fairness_metrics.py # Accuracy & Fairness pro Gruppe
│ ├── bias_analysis.py # Bias- & Risikoanalyse
│ ├── report_generator.py # Textbasierter Ethik-Report
│ └── main.py # Hauptpipeline
│
├── reports/
│ └── fairness_report.txt # automatisch generierter Report
│
├── dashboard/
│ └── app.py # optionales Streamlit-Dashboard
│
├── requirements.txt
└── README.md


---

## Zentrale Funktionen
- Fairness- & Accuracy-Messung pro Gruppe
- Bias-Erkennung (z. B. Ungleichbehandlung)
- Automatisierte ethische Textberichte
- Erweiterbar für Explainable AI & Audits
- Optionales Dashboard (Streamlit)

---

## Technologie-Stack
- Python
- NumPy / TensorFlow
- Scikit-learn
- Streamlit (optional)
- Responsible AI / Fairness Metrics

---

## Einordnung
Dieses Projekt versteht sich als **Analyse- und Lernwerkzeug**, nicht als automatisierte Entscheidungseinheit.  
Es unterstützt die kritische Auseinandersetzung mit KI-Systemen aus technischer und gesellschaftlicher Perspektive.

---

## Lizenz
Dieses Projekt dient Forschungs- und Lernzwecken.
